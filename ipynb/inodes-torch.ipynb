{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable, grad\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNBlock(torch.nn.Module):\n",
    "    def __init__(self, features):\n",
    "        \"\"\" Mini neural network\"\"\"\n",
    "        super(NNBlock, self).__init__()\n",
    "        self.features = features\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(self.features, x.shape)\n",
    "        x = F.leaky_relu(nn.Linear(self.features, self.features)(x))\n",
    "        x = F.leaky_relu(nn.Linear(self.features, self.features)(x))\n",
    "        x = F.leaky_relu(nn.Linear(self.features, self.features)(x))\n",
    "        return x\n",
    "        \n",
    "class InvertibleBlock(torch.nn.Module):\n",
    "    def __init__(self, features):\n",
    "        \"\"\" Invertible block for invertible neural network\n",
    "        \"\"\"\n",
    "        super(InvertibleBlock, self).__init__()\n",
    "        self.features = features\n",
    "        self.s1 = NNBlock(self.features//2)\n",
    "        self.s2 = NNBlock(self.features//2)\n",
    "        self.t1 = NNBlock(self.features//2)\n",
    "        self.t2 = NNBlock(self.features//2)\n",
    "\n",
    "    def forward(self, u):\n",
    "        \"\"\" Prediction step for invertible block\"\"\"        \n",
    "        u1, u2 = torch.split(u, 2, dim=1)\n",
    "        v1 = u1 * torch.exp(self.s2(u2)) + self.t2(u2)\n",
    "        v2 = u2 * torch.exp(self.s2(u1)) + self.t2(u1)\n",
    "        return torch.cat((v1, v2), dim=1)\n",
    "            \n",
    "    def invert(self, v):\n",
    "        \"\"\" Inverse prediction step for invertible block \"\"\"\n",
    "        v1, v2 = torch.split(v, 2, dim=1)\n",
    "        u2 = (v2 - self.t1(v1)) * torch.exp(-self.s1(v1))\n",
    "        u1 = (v1 - self.t2(v2)) * torch.exp(-self.s2(u2))\n",
    "        return torch.cat((u1, u2), dim=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "r1, r2 = 0, 10\n",
    "N = 100\n",
    "x = (r1 - r2) * torch.rand(N, D) + r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Linear(D, 1)(NNBlock(D)(nn.Linear(1, D)(torch.rand(N, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 4\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, D), \n",
    "    InvertibleBlock(D),\n",
    "    nn.Linear(D, 1)    \n",
    ")\n",
    "\n",
    "def loss_function(dFdx, logfx, x):\n",
    "    err = dFdx(x) * torch.exp(x**2/2) - logfx(x)\n",
    "    mse = torch.mean(torch.pow(err, 2))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfx = lambda x: (x - 2)**2 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'grad_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-f9d48dbdc4ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdFdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdFdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogfx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mmvec/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    589\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 591\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'grad_fn'"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "\n",
    "for i in tqdm.tqdm(range(epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    dFdx = model.grad_fn\n",
    "    loss = loss_function(dFdx, logfx, x)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.1739, 6.4259, 2.1677],\n",
       "        [7.8291, 6.7644, 8.2152],\n",
       "        [1.7953, 9.0421, 5.4770],\n",
       "        [1.3593, 9.2200, 6.7415],\n",
       "        [0.3938, 6.8967, 7.2334],\n",
       "        [1.7706, 3.1816, 7.4935],\n",
       "        [2.4664, 7.1811, 2.0965],\n",
       "        [7.6287, 8.5933, 7.4886],\n",
       "        [2.9009, 4.4174, 9.5906],\n",
       "        [3.2544, 6.6561, 9.7100],\n",
       "        [1.3539, 3.6694, 2.0668],\n",
       "        [2.0109, 1.5469, 9.8021],\n",
       "        [5.5447, 7.2284, 3.8696],\n",
       "        [6.4288, 6.3455, 6.5286],\n",
       "        [7.8471, 7.9702, 8.0500],\n",
       "        [0.5765, 0.9542, 8.0135],\n",
       "        [9.7116, 4.6032, 9.8829],\n",
       "        [9.3068, 1.4064, 3.4627],\n",
       "        [3.1410, 5.7822, 4.8473],\n",
       "        [3.9539, 2.4349, 8.5069],\n",
       "        [6.4294, 2.0363, 7.3910],\n",
       "        [5.6892, 3.5412, 2.2405],\n",
       "        [0.5620, 1.1726, 2.3146],\n",
       "        [6.0615, 6.0958, 7.3219],\n",
       "        [1.4351, 1.0259, 2.4657],\n",
       "        [4.1600, 3.1493, 1.1988],\n",
       "        [9.1426, 3.7643, 2.0887],\n",
       "        [3.3389, 9.2688, 1.2136],\n",
       "        [7.5713, 3.5864, 3.9415],\n",
       "        [2.8361, 1.0211, 4.9401],\n",
       "        [8.5477, 2.7453, 8.2592],\n",
       "        [1.8823, 5.2381, 6.3435],\n",
       "        [4.6151, 9.9050, 6.9805],\n",
       "        [5.5019, 0.3983, 7.2880],\n",
       "        [5.8332, 2.9676, 8.0181],\n",
       "        [0.2931, 1.3522, 7.1661],\n",
       "        [6.0762, 5.3653, 1.6679],\n",
       "        [4.5469, 4.2051, 1.9797],\n",
       "        [5.7156, 8.0521, 7.0040],\n",
       "        [6.4142, 0.0668, 5.1694],\n",
       "        [7.2957, 0.0868, 6.6766],\n",
       "        [6.2036, 4.0671, 2.7403],\n",
       "        [2.9453, 2.9464, 2.0815],\n",
       "        [5.0709, 0.1756, 3.4790],\n",
       "        [1.1827, 7.4943, 2.5720],\n",
       "        [6.7265, 8.9337, 7.2737],\n",
       "        [1.6353, 9.7196, 2.5086],\n",
       "        [4.7268, 0.3675, 0.3341],\n",
       "        [8.8093, 3.4915, 6.9326],\n",
       "        [6.3348, 4.1191, 1.2704],\n",
       "        [7.5578, 2.1204, 8.2011],\n",
       "        [2.2086, 2.0138, 3.3364],\n",
       "        [2.2653, 5.8131, 4.4409],\n",
       "        [7.7444, 8.4462, 6.0021],\n",
       "        [5.9297, 9.3736, 4.4984],\n",
       "        [4.9142, 6.4642, 8.5530],\n",
       "        [9.6357, 6.5003, 1.3375],\n",
       "        [6.8962, 4.9183, 4.4627],\n",
       "        [9.6398, 8.2002, 7.7444],\n",
       "        [2.0313, 4.7676, 1.2096],\n",
       "        [7.0883, 7.7460, 7.6340],\n",
       "        [6.5555, 7.7814, 2.4974],\n",
       "        [1.7224, 6.7638, 2.5190],\n",
       "        [0.0692, 2.7430, 4.8702],\n",
       "        [7.3072, 2.3265, 3.6631],\n",
       "        [6.3735, 1.1054, 1.5403],\n",
       "        [8.8001, 4.3834, 8.5901],\n",
       "        [4.9833, 6.0558, 5.3750],\n",
       "        [4.7760, 1.1205, 9.2880],\n",
       "        [2.0668, 2.7115, 5.3833],\n",
       "        [5.9548, 8.0592, 4.1160],\n",
       "        [6.7831, 3.0818, 1.0613],\n",
       "        [5.3385, 8.0012, 0.1472],\n",
       "        [1.9859, 2.4040, 0.9517],\n",
       "        [5.4907, 7.1133, 7.1174],\n",
       "        [0.7230, 1.5293, 5.1794],\n",
       "        [1.3850, 4.3418, 7.2197],\n",
       "        [0.5379, 4.3059, 4.2270],\n",
       "        [3.5386, 0.1333, 3.5228],\n",
       "        [5.7023, 7.9250, 8.6173],\n",
       "        [4.4040, 8.1391, 1.8468],\n",
       "        [6.7899, 8.3732, 8.9040],\n",
       "        [7.5173, 8.3791, 2.1541],\n",
       "        [0.4379, 8.5491, 5.4632],\n",
       "        [2.0024, 0.3400, 8.7996],\n",
       "        [5.9617, 7.5323, 3.9508],\n",
       "        [9.9067, 4.9329, 6.9667],\n",
       "        [0.7415, 0.0404, 0.7421],\n",
       "        [0.4379, 3.5240, 8.5853],\n",
       "        [1.5628, 0.3632, 3.7157],\n",
       "        [4.7547, 6.6654, 5.6850],\n",
       "        [9.4053, 0.2166, 1.7373],\n",
       "        [9.0546, 0.3125, 2.5365],\n",
       "        [1.7745, 0.8416, 9.6566],\n",
       "        [0.0851, 3.6119, 6.9642],\n",
       "        [7.4662, 3.0553, 8.1187],\n",
       "        [0.8962, 9.8026, 4.2291],\n",
       "        [1.4810, 2.7554, 9.1346],\n",
       "        [3.1019, 8.9444, 0.2617],\n",
       "        [5.4283, 0.2646, 0.5623]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
